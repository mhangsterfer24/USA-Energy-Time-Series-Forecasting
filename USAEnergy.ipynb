{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3268cf-0e84-4f54-a57f-fcf0f97138c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "from datetime import datetime\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.statespace.varmax import VARMAX\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import select\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeb82bb-6815-4cb1-bbaa-d62802353f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE THE DATABASE CREDENTIALS\n",
    "load_dotenv('env.env')\n",
    "user = os.getenv('user')\n",
    "password = os.getenv('password')\n",
    "host = os.getenv('host')\n",
    "port = os.getenv('port')\n",
    "database = os.getenv('database')\n",
    "\n",
    "#replace <user>, <password>, <host>, and <port> with your MySQL credentials\n",
    "cnx = create_engine(f'mysql+pymysql://{user}:{password}@{host}:{port}/{database}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26263540-c2cc-43c9-9e56-75a9b9d6ea1a",
   "metadata": {},
   "source": [
    "## Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc2968b-f133-4f48-8364-3e29fac10d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Tables in\n",
    "df = pd.read_sql_table('ElecNetGen', cnx)\n",
    "df2 = pd.read_sql_table('USA_Monthly_Avg_Temp', cnx)\n",
    "\n",
    "# Put Temp column into main dataframe\n",
    "df['Temp'] = df2['Monthly Avg Temp-F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe503063-00f6-4350-9250-5c8f202abff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Date column with proper formatting from period columns\n",
    "df['Date'] = pd.to_datetime(df['period'], format=\"%Y-%m\")\n",
    "\n",
    "# set index to Date\n",
    "df.set_index(df['Date'], inplace=True)\n",
    "df.drop('Date', axis=1, inplace=True)\n",
    "df.drop('period', axis=1, inplace=True)\n",
    "\n",
    "# Saying treat the index as months ('MS') and start at row 1 instead of the headings .fe1\n",
    "df.index.fe1= 'MS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d516be-74b6-402f-b926-d8b44ebe4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable to manager iterations through the columns\n",
    "cols = ['Coal', 'Hydroelectric','NaturalGas' , 'Nuclear', 'Petroleum','Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0ff7f7-8fa2-4605-aa87-9d2b406155d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to perform Augmented Dickey Fuller test - stationary if p-value below less than 0.05\n",
    "def Augmented_Dickey_Fuller(data):\n",
    "    res = adfuller(data)\n",
    "    print(f'p-value: {res[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e428ff0-8859-450d-95fd-13ba752533ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Wind', 'Solar'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade1dfe0-d63a-4fb2-90d9-685fdad4d560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Difference data\n",
    "diffquant=1\n",
    "for col in cols:\n",
    "    df[f'diff_{col}'] = df[col].diff(periods=diffquant).dropna()\n",
    "    \n",
    "# Delete NaN rows from differencing data so doesn't error out models\n",
    "df = df.iloc[diffquant: , :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f4763-6f8b-408a-a954-8c627174877f",
   "metadata": {},
   "source": [
    "## Augmented Dickey-Fuller Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Differenced columns\n",
    "cols = ['diff_Coal', 'diff_Hydroelectric', 'diff_NaturalGas', 'diff_Nuclear', 'diff_Petroleum', 'diff_Temp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59138952-afa3-4fe4-af25-9438934b686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data is stationary\n",
    "for col in cols:\n",
    "    print(f'{col} ')\n",
    "    Augmented_Dickey_Fuller(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594d5ef-f1aa-480b-b645-f7eafd62970b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test set for both datasets\n",
    "test_count = 60\n",
    "train = df.iloc[:-test_count].copy()\n",
    "test = df.iloc[-test_count:].copy()\n",
    "\n",
    "# Used to index original dataframe for both the train and test sets\n",
    "train_index = df.index <= train.index[-1]\n",
    "test_index = df.index > train.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47d119f-dfa5-4dbd-9f0b-95c2192e9a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through columns and create a scaled version of them so we can compare\n",
    "scaler_dic = {}\n",
    "for col in cols:\n",
    "    scaler_col = StandardScaler()\n",
    "    scaler_dic[f\"Scaled_{col}\"] = scaler_col\n",
    "    train[f'Scaled_{col}'] = scaler_col.fit_transform(train[[col]])\n",
    "    test[f'Scaled_{col}'] = scaler_col.transform(test[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac41c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables for scaled and stationary data\n",
    "cols = ['Scaled_diff_Coal', 'Scaled_diff_Hydroelectric', 'Scaled_diff_NaturalGas', 'Scaled_diff_Temp',\n",
    " 'Scaled_diff_Nuclear', 'Scaled_diff_Petroleum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42f779f-e7ff-4913-be7c-9d79665108ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add scaled features to original df\n",
    "for col in cols:\n",
    "    df.loc[train_index, col] = train[col]\n",
    "    df.loc[test_index, col] = test[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b000a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in time components as features\n",
    "def create_features(df):\n",
    "    df = df.copy()\n",
    "    df['quarter'] = df.index.quarter\n",
    "    df['month'] = df.index.month\n",
    "    df['year'] = df.index.year\n",
    "    return df\n",
    "# Add in time as features\n",
    "df = create_features(df)\n",
    "train = create_features(train)\n",
    "test = create_features(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c4facc",
   "metadata": {},
   "source": [
    "## Clean DataFrame for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81181ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'Scaled_diff_Temp'\n",
    "\n",
    "arima = ARIMA(df[TARGET], order=(24,0,24))\n",
    "arima_result=arima.fit()\n",
    "prediction_result=arima_result.get_forecast(test_count)\n",
    "\n",
    "# Create dataframe for 5 year forecast\n",
    "future = pd.date_range('2023-01-01', '2027-12-01', freq = 'MS')\n",
    "future_df = pd.DataFrame(index=future)\n",
    "future_df = create_features(future_df)\n",
    "\n",
    "# For ARIMA\n",
    "future_df['pred_Temp'] = predictions = prediction_result.predicted_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbee770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for all models to use\n",
    "cols = ['Scaled_diff_Coal', 'Scaled_diff_Hydroelectric', 'Scaled_diff_NaturalGas', 'Scaled_diff_Temp',\n",
    " 'Scaled_diff_Nuclear', 'Scaled_diff_Petroleum']\n",
    "original_cols = ['Coal','Hydroelectric', 'NaturalGas', 'Temp', 'Nuclear', 'Petroleum']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c421ba7",
   "metadata": {},
   "source": [
    "## ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b39ed-ac8e-4882-83ee-4c8df7c94336",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ARIMA_df = test.copy()\n",
    "i = 0\n",
    "\n",
    "for col in cols:\n",
    "    TARGET = col\n",
    "    \n",
    "    arima = ARIMA(train[col], order=(12,0,12))\n",
    "    arima_result=arima.fit()\n",
    "    ARIMA_prediction_result=arima_result.get_forecast(test_count)\n",
    "    ARIMA_predictions = ARIMA_prediction_result.predicted_mean.to_numpy()\n",
    "    \n",
    "    # Scale back data\n",
    "    ARIMA_df[f'pred_inv_{col}'] = scaler_dic[TARGET].inverse_transform(ARIMA_predictions.reshape(-1,1))\n",
    "\n",
    "    ARIMA_forecast = []\n",
    "    ARIMA_last_value = train.iloc[-1][f'{original_cols[i]}']\n",
    "    for x in range(len(test)):\n",
    "        ARIMA_hold = ARIMA_df[f'pred_inv_{col}'][-test_count:][x] + ARIMA_last_value\n",
    "        ARIMA_forecast.append(ARIMA_hold)\n",
    "        ARIMA_last_value = ARIMA_hold\n",
    "    ARIMA_df[f'forecast_{original_cols[i]}'] = ARIMA_forecast\n",
    "\n",
    "    ARIMA_disp = [original_cols[i], f'forecast_{original_cols[i]}']\n",
    "    ARIMA_df[ARIMA_disp].plot(figsize=(10,5), title=f'ARIMA {original_cols[i]}',ylabel='Million Kilowatthours')\n",
    "\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "    # Checks mean squared and r-squared\n",
    "    print(f\"{col} Train RMSE:\", mean_squared_error(df.loc[train_index,col],  arima_result.fittedvalues, squared=False))\n",
    "    print(f\"{col} Test RMSE:\", round(mean_squared_error(df.loc[test_index,col], ARIMA_prediction_result.predicted_mean,squared=False),4))\n",
    "    print(f\"{col} Train R^2:\", r2_score(df.loc[train_index,col],  arima_result.fittedvalues))\n",
    "    print(f\"{col} Test R^2:\", round(r2_score(df.loc[test_index,col], ARIMA_prediction_result.predicted_mean),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608ca59e",
   "metadata": {},
   "source": [
    "## 5-Year Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d356d478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "ARIMA_future_df = future_df.copy()\n",
    "for col in cols:\n",
    "    TARGET = col\n",
    "\n",
    "    arima = ARIMA(df[TARGET], order=(24,0,24))\n",
    "                                     \n",
    "    arima_fcast_res=arima.fit()\n",
    "    ARIMA_fcast_pred_res=arima_fcast_res.get_forecast(test_count)\n",
    "    ARIMA_fcast_pred = ARIMA_fcast_pred_res.predicted_mean.to_numpy()\n",
    "\n",
    "    # Scale back data\n",
    "    ARIMA_future_df[f'pred_inv_{col}'] = scaler_dic[TARGET].inverse_transform(ARIMA_fcast_pred.reshape(-1,1))\n",
    "    \n",
    "    # Last - known train value\n",
    "    ARIMA_fcast = []\n",
    "    ARIMA_fcast_last_value = test.iloc[-1][original_cols[i]]\n",
    "    for x in range(len(test)):\n",
    "        ARIMA_fcast_hold = ARIMA_future_df[f'pred_inv_{col}'][-test_count:][x] + ARIMA_fcast_last_value\n",
    "        ARIMA_fcast.append(ARIMA_fcast_hold)\n",
    "        ARIMA_fcast_last_value = ARIMA_fcast_hold\n",
    "    ARIMA_future_df[f'forecast_{original_cols[i]}'] = ARIMA_fcast\n",
    "\n",
    "    ARIMA_disp = [f'forecast_{original_cols[i]}']\n",
    "    ARIMA_future_df[ARIMA_disp].plot(figsize=(15,5))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502111ca-27d0-4dba-ba01-d8b2c1661bce",
   "metadata": {},
   "source": [
    "## VARMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aeca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns for VARMAX\n",
    "VARMAX_cols = cols.copy()\n",
    "VARMAX_original_cols = original_cols.copy()\n",
    "VARMAX_cols.remove('Scaled_diff_Temp')\n",
    "VARMAX_original_cols.remove('Temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd64070d-afe2-4fdd-a01c-7c0db0221145",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "# Use this to train model and save models in pickle file so don't need to retrain each time.\n",
    "\n",
    "# for col in VARMAX_cols:\n",
    "#     points = [col, 'Scaled_diff_Temp']\n",
    "#     model = VARMAX(train[points],order = (12,12))\n",
    "#     res = model.fit(maxiter=100)\n",
    "#     with open(f'{col}_results_24.pkl', 'wb') as file:\n",
    "#         pickle.dump(res, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a048b4e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "VARMAX_df = test.copy()\n",
    "i = 0\n",
    "\n",
    "for col in VARMAX_cols:\n",
    "    TARGET = col\n",
    "    \n",
    "    with open(f'{col}_results.pkl', 'rb') as file: \n",
    "        VARMAX_res = pickle.load(file)\n",
    "    VARMAX_fcast = VARMAX_res.get_forecast(test_count)\n",
    "    \n",
    "    VARMAX_df[f'{col}_prediction'] = VARMAX_fcast.predicted_mean[col]\n",
    "    VARMAX_predictions = VARMAX_df[f'{col}_prediction'].to_numpy()\n",
    "    \n",
    "    # Scale back data\n",
    "    VARMAX_df[f'pred_inv_{col}'] = scaler_dic[TARGET].inverse_transform(VARMAX_predictions.reshape(-1,1))\n",
    "    \n",
    "    VARAMX_forecast = []\n",
    "    VARMAX_last = train.iloc[-1][f'{VARMAX_original_cols[i]}']\n",
    "    for x in range(len(test)):\n",
    "        VARMAX_hold = VARMAX_df[f'pred_inv_{col}'][-test_count:][x] + VARMAX_last\n",
    "        VARAMX_forecast.append(VARMAX_hold)\n",
    "        VARMAX_last = VARMAX_hold\n",
    "    VARMAX_df[f'forecast_{VARMAX_original_cols[i]}'] = VARAMX_forecast\n",
    "\n",
    "    VARMAX_disp = [VARMAX_original_cols[i], f'forecast_{VARMAX_original_cols[i]}']\n",
    "    VARMAX_df[VARMAX_disp].plot(figsize = (10,5), title=(f'VARMAX {VARMAX_original_cols[i]}'),\n",
    "                                    ylabel='Million Kilowatthours')\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    # Checks mean squared and r-squared\n",
    "    print(f\"{col} Train RMSE:\", mean_squared_error(df.loc[train_index, col],VARMAX_res.fittedvalues[col],squared=False))\n",
    "    print(f\"{col} Test RMSE:\", round(mean_squared_error(df.loc[test_index,col], VARMAX_fcast.predicted_mean[col],squared=False),4))\n",
    "    print(f\"{col} Train R^2:\", r2_score(df.loc[train_index, col],VARMAX_res.fittedvalues[col]))\n",
    "    print(f\"{col} Test R^2:\", round(r2_score(df.loc[test_index,col], VARMAX_fcast.predicted_mean[col]),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b56354",
   "metadata": {},
   "source": [
    "## VARMAX 5-Year Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15a8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in VARMAX_cols:\n",
    "#     points = [col, 'Scaled_diff_Temp']\n",
    "#     VARMAX_fcast_model = VARMAX(df[points],order = (12,12))\n",
    "#     VARMAX_fcast_res = VARMAX_fcast_model.fit(maxiter=100)\n",
    "#     with open(f'fcast_{col}_results.pkl', 'wb') as file:\n",
    "#         pickle.dump(VARMAX_fcast_res, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2acbfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "VARMAX_future_df = future_df.copy()\n",
    "i = 0\n",
    "\n",
    "for col in VARMAX_cols:\n",
    "    TARGET = col\n",
    "    \n",
    "    with open(f'fcast_{col}_results.pkl', 'rb') as file: \n",
    "        VARMAX_fcast_res = pickle.load(file)\n",
    "    VARMAX_5_fcast = VARMAX_fcast_res.get_forecast(test_count)\n",
    "    \n",
    "    VARMAX_future_df[f'{col}_prediction'] = VARMAX_5_fcast.predicted_mean[col]\n",
    "    VARMAX_5_predictions = VARMAX_future_df[f'{col}_prediction'].to_numpy()\n",
    "    \n",
    "    # Scale back data\n",
    "    VARMAX_future_df[f'pred_inv_{col}'] = scaler_dic[TARGET].inverse_transform(VARMAX_5_predictions.reshape(-1,1))\n",
    "    \n",
    "    VARAMX_5_forecast = []\n",
    "    VARMAX_5_last = test.iloc[-1][f'{VARMAX_original_cols[i]}']\n",
    "    for x in range(len(test)):\n",
    "        VARMAX_5_hold = VARMAX_future_df[f'pred_inv_{col}'][-test_count:][x] + VARMAX_5_last\n",
    "        VARAMX_5_forecast.append(VARMAX_5_hold)\n",
    "        VARMAX_5_last = VARMAX_5_hold\n",
    "    VARMAX_future_df[f'forecast_{VARMAX_original_cols[i]}'] = VARAMX_5_forecast\n",
    "\n",
    "    VARMAX_5_disp = [f'forecast_{VARMAX_original_cols[i]}']\n",
    "    VARMAX_future_df[VARMAX_5_disp].plot(figsize=(15,5))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a30bf",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5e1db0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_RMSE_Scores = []\n",
    "xgb_df = df.copy()\n",
    "xgb_test = test.copy()\n",
    "i = 0\n",
    "\n",
    "for col in cols:\n",
    "\n",
    "    TARGET = col\n",
    "    X_train = train[['quarter', 'month','year', 'Scaled_diff_Temp']]\n",
    "    y_train = train[TARGET]\n",
    "    X_test = test[['quarter', 'month','year', 'Scaled_diff_Temp']]\n",
    "    y_test = test[TARGET]\n",
    "\n",
    "    # Create the model\n",
    "    xgb_res = xgb.XGBRegressor(booster='gbtree',    \n",
    "                           n_estimators=800,\n",
    "                           early_stopping_rounds=40,\n",
    "                           objective='reg:squarederror',\n",
    "                           max_depth=3,\n",
    "                           learning_rate=0.05)\n",
    "    xgb_res.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],verbose=False)\n",
    "\n",
    "    # Forecast on Test and Train\n",
    "    xgb_test['prediction'] = xgb_res.predict(X_test)\n",
    "    xgb_df.loc[train_index,'train_prediction'] = xgb_res.predict(X_train)\n",
    "    xgb_pred = xgb_test['prediction'].to_numpy()\n",
    "    xgb_train_pred = xgb_df.loc[train_index,'train_prediction'].to_numpy()\n",
    "\n",
    "    # Scale back data\n",
    "    xgb_test[f'pred_inv_{col}'] = scaler_dic[TARGET].inverse_transform(xgb_pred.reshape(-1,1))\n",
    "\n",
    "    # Last - known train value\n",
    "    xgb_forecast = []\n",
    "    xgb_last = train.iloc[-1][f'{original_cols[i]}']\n",
    "    for x in range(len(test)):\n",
    "        xgb_hold = xgb_test[f'pred_inv_{col}'][-test_count:][x] + xgb_last\n",
    "        xgb_forecast.append(xgb_hold)\n",
    "        xgb_last = xgb_hold\n",
    "    xgb_test[f'forecast_{original_cols[i]}'] = xgb_forecast\n",
    "\n",
    "    xgb_disp = [original_cols[i], f'forecast_{original_cols[i]}']\n",
    "    xgb_test[xgb_disp].plot(figsize=(10,5), title= f'XGB {original_cols[i]}',ylabel='Million Kilowatthours')\n",
    "\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    # Checks mean squared and r-squared\n",
    "    print(f\"{col} Train RMSE:\", mean_squared_error(train[TARGET], xgb_df.loc[train_index,'train_prediction'], squared=False))\n",
    "    print(f\"{col} Test RMSE:\", round(mean_squared_error(test[TARGET], xgb_test['prediction'],squared=False),4))\n",
    "    print(f\"{col} Train R^2:\", r2_score(train[TARGET],  xgb_df.loc[train_index,'train_prediction']))\n",
    "    print(f\"{col} Test R^2:\", round(r2_score(test[TARGET], xgb_test['prediction']),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94588883",
   "metadata": {},
   "source": [
    "### 5 Year Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2dcf90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "future_df_xgb = future_df.copy()\n",
    "future_df_xgb.rename({'pred_Temp':'Scaled_diff_Temp'},axis=1, inplace=True)\n",
    "i = 0\n",
    "\n",
    "for col in cols:\n",
    "    FEATURES = ['quarter', 'month', 'year', 'Scaled_diff_Temp']\n",
    "    TARGET = col\n",
    "\n",
    "    X_all = df[FEATURES]\n",
    "    y_all = df[TARGET]\n",
    "\n",
    "    # Create the model\n",
    "    xgb_fcast_reg = xgb.XGBRegressor(base_score=0.5, booster='gbtree',    \n",
    "                           n_estimators=800,\n",
    "                           early_stopping_rounds=40,\n",
    "                           objective='reg:squarederror',\n",
    "                           max_depth=3,\n",
    "                           learning_rate=0.05)\n",
    "    xgb_fcast_reg.fit(X_all, y_all, eval_set=[(X_all, y_all)], verbose=False)\n",
    "\n",
    "    # For XGBoost\n",
    "    future_df_xgb['pred'] = xgb_fcast_pred = xgb_fcast_reg.predict(future_df_xgb[FEATURES])\n",
    "\n",
    "    # Scale back data\n",
    "    future_df_xgb[f'pred_inv_{col}'] = scaler_dic[TARGET].inverse_transform(xgb_fcast_pred.reshape(-1,1))\n",
    "    \n",
    "    # Last - known train value\n",
    "    xgb_fcast = []\n",
    "    xgb_fcast_last_value = test.iloc[-1][original_cols[i]]\n",
    "    for x in range(len(test)):\n",
    "        xgb_fcast_hold = future_df_xgb[f'pred_inv_Scaled_diff_{original_cols[i]}'][-test_count:][x] + xgb_fcast_last_value\n",
    "        xgb_fcast.append(xgb_fcast_hold)\n",
    "        xgb_fcast_last_value = xgb_fcast_hold\n",
    "    future_df_xgb[f'forecast_{original_cols[i]}'] = xgb_fcast\n",
    "\n",
    "    xgb_fcast_disp = [f'forecast_{original_cols[i]}']\n",
    "    future_df_xgb[xgb_fcast_disp].plot(figsize=(15,5))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f619f0",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9566e3d-2abc-48c0-80e9-0c39f2a7f9df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr_RMSE_Scores = []\n",
    "i = 0\n",
    "lr_test = test.copy()\n",
    "\n",
    "for col in cols:\n",
    "    TARGET = col\n",
    "    lr_model = LinearRegression()\n",
    "    X_train = train[['Scaled_diff_Temp', 'quarter', 'month', 'year']]\n",
    "    y_train = train[TARGET]\n",
    "    X_test = test[['Scaled_diff_Temp', 'quarter', 'month', 'year']]\n",
    "    y_test = test[TARGET]\n",
    "    \n",
    "    # fitting the model \n",
    "    lr_model.fit(X_train,y_train)\n",
    "\n",
    "    # making predictions \n",
    "    lr_pred_train = lr_model.predict(X_train)\n",
    "    lr_test['prediction'] = lr_pred = lr_model.predict(X_test)\n",
    "    \n",
    "    # Scale back data\n",
    "    lr_test[f'pred_inv_{col}'] = scaler_dic[TARGET].inverse_transform(lr_pred.reshape(-1,1))\n",
    "\n",
    "    # Last - known train value\n",
    "    lr_forecast = []\n",
    "    lr_last_value = train.iloc[-1][f'{original_cols[i]}']\n",
    "    for x in range(len(test)):\n",
    "        lr_hold = lr_test[f'pred_inv_{col}'][-test_count:][x] + lr_last_value\n",
    "        lr_forecast.append(lr_hold)\n",
    "        lr_last_value = lr_hold\n",
    "    lr_test[f'forecast_{original_cols[i]}'] = lr_forecast\n",
    "\n",
    "    lr_disp = [original_cols[i], f'forecast_{original_cols[i]}']\n",
    "    lr_test[lr_disp].plot(figsize=(10,5), title=f'LR_{original_cols[i]}',ylabel='Million Kilowatthours')\n",
    "\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "    # Checks mean squared and r-squared\n",
    "    print(f\"{col} Train RMSE:\", mean_squared_error(y_train, lr_pred_train, squared=False))\n",
    "    print(f\"{col} Test RMSE:\", round(mean_squared_error(y_test, lr_pred, squared=False),4))\n",
    "    print(f\"{col} Train R^2:\", r2_score(y_train, lr_pred_train))\n",
    "    print(f\"{col} Test R^2:\", round(r2_score(y_test, lr_pred),4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995bf0e4",
   "metadata": {},
   "source": [
    "### 5-Year Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee118d3d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create dataframe for 5 year forecast\n",
    "future_df_lr = future_df.copy()\n",
    "future_df_lr.rename({'pred_Temp':'Scaled_diff_Temp'},axis=1, inplace=True)\n",
    "i = 0\n",
    "\n",
    "for col in cols:\n",
    "    FEATURES = ['quarter', 'month', 'year', 'Scaled_diff_Temp']\n",
    "    TARGET = col\n",
    "\n",
    "    X_all = df[FEATURES]\n",
    "    y_all = df[TARGET]\n",
    "\n",
    "    # Create the model\n",
    "    lr_fcast_model = LinearRegression()\n",
    "    \n",
    "    lr_fcast_model.fit(X_all, y_all)\n",
    "\n",
    "    # For LR\n",
    "    future_df_lr['pred'] = lr_fcast_pred = lr_fcast_model.predict(future_df_lr[FEATURES])\n",
    "\n",
    "    # Scale back data\n",
    "    future_df_lr[f'pred_inv_{cols}'] = scaler_dic[TARGET].inverse_transform(lr_fcast_pred.reshape(-1,1))\n",
    "    \n",
    "    # Last - known train value\n",
    "    lr_5_fcast = []\n",
    "    lr_5_last_value = test.iloc[-1][original_cols[i]]\n",
    "    for x in range(len(test)):\n",
    "        lr_5_hold = future_df_lr[f'pred_inv_{cols}'][-test_count:][x] + lr_5_last_value\n",
    "        lr_5_fcast.append(lr_5_hold)\n",
    "        lr_5_last_value = lr_5_hold\n",
    "    future_df_lr[f'forecast_{original_cols[i]}'] = lr_5_fcast\n",
    "\n",
    "    lr_5_disp = [f'forecast_{original_cols[i]}']\n",
    "    future_df_lr[lr_5_disp].plot(figsize=(15,5))\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
